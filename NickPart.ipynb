{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from sklearn import datasets\n",
    "import copy\n",
    "\n",
    "# Load Classification Player Data\n",
    "\n",
    "data = []\n",
    "\n",
    "#Load Data\n",
    "with open('players_stats.csv') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "player_data_raw = np.array(data)\n",
    "\n",
    "# Remove labels\n",
    "player_data_uncentered_unnormalized = player_data_raw[1:].T[1:-1].T.astype(np.float)\n",
    "\n",
    "# Mean Center Data\n",
    "player_data_unnormalized = player_data_uncentered_unnormalized - np.mean(player_data_uncentered_unnormalized, axis=0)\n",
    "\n",
    "# Normalized data so there wouldnt be any overflow errors\n",
    "player_data = player_data_unnormalized / np.linalg.norm(player_data_unnormalized, axis=0)\n",
    "\n",
    "# Get labels\n",
    "player_labels = player_data_raw.T[-1].T[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classification Iris Data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data_uncentered_unnormalized = iris.data\n",
    "\n",
    "# Mean Center\n",
    "iris_data_unnormalized = iris_data_uncentered_unnormalized - np.mean(iris_data_uncentered_unnormalized, axis=0)\n",
    "\n",
    "# Normalize data\n",
    "iris_data = iris_data_unnormalized / np.linalg.norm(iris_data_unnormalized, axis=0)\n",
    "\n",
    "# Get Labels\n",
    "iris_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Clustering Seed Data\n",
    "\n",
    "data = []\n",
    "\n",
    "#Load Data from file\n",
    "with open('Seed_Data.csv') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "seed_data_raw = np.array(data)\n",
    "\n",
    "# Remove Expected Clusters\n",
    "seed_data_uncentered = seed_data_raw[1:].T[:-1].T.astype(np.float)\n",
    "\n",
    "# Mean Center Data\n",
    "seed_data = seed_data_uncentered - np.mean(seed_data_uncentered, axis=0)\n",
    "\n",
    "# Get Expected Clusters\n",
    "seed_label = seed_data_raw.T[-1].T[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the Multivariate Gaussian distribution for each class\n",
    "\n",
    "def naive_bayes_learn(X, Y):\n",
    "    #Determine the classes we are classifying\n",
    "    classes = []\n",
    "    data = []\n",
    "    for i in Y:\n",
    "        if i not in classes:\n",
    "            classes.append(i)\n",
    "            data.append([])\n",
    "    \n",
    "    #Split up data into arrays by class\n",
    "    for index, info in enumerate(X):\n",
    "        data[classes.index(Y[index])].append(info)\n",
    "    \n",
    "    #Calculate mean and covariance by class\n",
    "    mean = []\n",
    "    cov = []\n",
    "    for cls in data:\n",
    "        mean.append(np.mean(cls, axis=0))\n",
    "        cov.append(np.cov(np.array(cls).T))\n",
    "    \n",
    "    return classes, mean, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Multivariate Gaussian based on the mean vector, covariance vector, and data sample\n",
    "\n",
    "def multi_gauss(u, E, x):\n",
    "    sub = np.subtract(x, u)\n",
    "    top = math.exp(-0.5 * (sub.T @ np.linalg.inv(E) @ sub))\n",
    "    bottom = math.sqrt(np.power(2*np.pi, len(x)) * abs(np.linalg.det(E)))\n",
    "    return top / bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a set of X data samples given the outputs of the learn function\n",
    "\n",
    "def naive_bayes_predict(classes, mean, cov, X):\n",
    "    # Check each class to see if it has highest probability\n",
    "    pred = []\n",
    "    for data in X:\n",
    "        preds = []\n",
    "        # For every element, test every class\n",
    "        for index, cls in enumerate(classes):\n",
    "            preds.append(multi_gauss(mean[index], cov[index], data))\n",
    "        # Append highest probability class, aka the prediction\n",
    "        pred.append(classes[np.argmax(preds)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match, Missed:  325 165\n"
     ]
    }
   ],
   "source": [
    "# Player classifier trained on all data\n",
    "player_classes, player_mean, player_cov = naive_bayes_learn(player_data, player_labels)\n",
    "pred = naive_bayes_predict(player_classes, player_mean, player_cov, player_data)\n",
    "match = 0\n",
    "missed = 0\n",
    "for index in range(0, len(pred)):\n",
    "    if pred[index] == player_labels[index]:\n",
    "        match += 1\n",
    "    else:\n",
    "        missed += 1\n",
    "print(\"Match, Missed: \", match, missed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed classification on the entire dataset to determine if the algorithm was working, and to determine how well it would perform for this set of data. I also tried performing classification with un-normalized data, but this resulted in an overflow error in the exponent of the multivariate gaussian, so I opted to normalize the data in order to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match, Missed:  147 3\n"
     ]
    }
   ],
   "source": [
    "# Iris classifier trained on all data\n",
    "iris_classes, iris_mean, iris_cov = naive_bayes_learn(iris_data, iris_label)\n",
    "pred = naive_bayes_predict(iris_classes, iris_mean, iris_cov, iris_data)\n",
    "match = 0\n",
    "missed = 0\n",
    "for index in range(0, len(pred)):\n",
    "    if pred[index] == iris_label[index]:\n",
    "        match += 1\n",
    "    else:\n",
    "        missed += 1\n",
    "print(\"Match, Missed: \", match, missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster dataset X into k clusters using k_means clustering\n",
    "\n",
    "def k_means(k, X):\n",
    "    \n",
    "    #Create k clusters and randomly initalize them\n",
    "    clusters = []\n",
    "    for clus in range(0, k):\n",
    "        clusters.append([])\n",
    "    for index, x in enumerate(X):\n",
    "        clusters[index % k].append(x)\n",
    "    \n",
    "    #Start Kmeans loop\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        # Keep track of previous clusters\n",
    "        prev_clusters = copy.deepcopy(clusters)\n",
    "\n",
    "        # Calculate centroid of clusters\n",
    "        cluster_means = []\n",
    "        for cluster in prev_clusters:            \n",
    "            cluster_means.append(np.mean(cluster, axis=0))\n",
    "\n",
    "        # Initalize new blank clusters\n",
    "        clusters = []\n",
    "        for clus in range(0, k):\n",
    "            clusters.append([])\n",
    "        \n",
    "        # Reset Convergence Test\n",
    "        converged = True\n",
    "        \n",
    "        # Move all elements to cluster with closest centroid\n",
    "        for index, cluster in enumerate(prev_clusters):\n",
    "            for data in cluster:\n",
    "#                 print(\"Data: \", data)\n",
    "                dist = []\n",
    "                data = np.array(data)\n",
    "                # Calculate distance from all centroids\n",
    "                for mean in cluster_means:\n",
    "                    dist.append(np.linalg.norm(mean - data))\n",
    "#                 print(\"Distances: \", dist)\n",
    "#                 print(dist)\n",
    "                new_index = np.argmin(dist)\n",
    "                clusters[new_index].append(data)\n",
    "#                 print(\"Data moved to: \", new_index)\n",
    "                # If any datapoint was moved to a different cluster, no convergence\n",
    "                if index != new_index:\n",
    "                    converged = False\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Cluster:  0 maps with estimated Cluster:  1\n",
      "Num Matched:  57 Num Estimated:  67 Num Given:  70\n",
      "\n",
      "Given Cluster:  1 maps with estimated Cluster:  0\n",
      "Num Matched:  60 Num Estimated:  61 Num Given:  70\n",
      "\n",
      "Given Cluster:  2 maps with estimated Cluster:  2\n",
      "Num Matched:  70 Num Estimated:  82 Num Given:  70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cluster the seed database\n",
    "\n",
    "predicted_clusters = k_means(3, seed_data)\n",
    "\n",
    "#Determine the clusters\n",
    "clusters = []\n",
    "data = []\n",
    "for i in seed_label:\n",
    "    if i not in clusters:\n",
    "        clusters.append(i)\n",
    "        data.append([])\n",
    "#Split up data into arrays by cluster\n",
    "for index, info in enumerate(seed_data):\n",
    "    data[clusters.index(seed_label[index])].append(info)\n",
    "    \n",
    "# Compare all given clustes with estimated clusters in order to determine performance\n",
    "cluster_map = []\n",
    "for known_index, cluster in enumerate(data):\n",
    "    # Compare known cluster against all possible clusters\n",
    "    max_matches = 0\n",
    "    best_match = 0\n",
    "    for index, pred in enumerate(predicted_clusters):\n",
    "        matches = 0\n",
    "        # Check every element if it is in the predicted cluster\n",
    "        for data1 in cluster:\n",
    "            for every in pred:\n",
    "                data1 = np.array(data1)\n",
    "                every = np.array(every)\n",
    "                if np.array_equal(data1, every):\n",
    "                    matches += 1\n",
    "                    break\n",
    "#         print(\"Cluster: \", index, \"matched: \", matches, \"times with given Cluster:\", known_index)\n",
    "        if matches > max_matches:\n",
    "            max_matches = matches\n",
    "            best_match = index\n",
    "    cluster_map.append(best_match)\n",
    "#     print()\n",
    "\n",
    "# Print the matches\n",
    "for index, i in enumerate(cluster_map):\n",
    "    print(\"Given Cluster: \", index, \"maps with estimated Cluster: \", i)\n",
    "    matches = 0\n",
    "    for data1 in data[index]:\n",
    "        for every in predicted_clusters[i]:\n",
    "            data1 = np.array(data1)\n",
    "            every = np.array(every)\n",
    "            if np.array_equal(data1, every):\n",
    "                matches += 1\n",
    "                break\n",
    "    print(\"Num Matched: \", matches, \"Num Estimated: \", len(predicted_clusters[i]), \"Num Given: \", len(data[index]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match, Missed:  35 47 Accuracy:  0.4268292682926829\n",
      "Match, Missed:  31 51 Accuracy:  0.3780487804878049\n",
      "Match, Missed:  36 46 Accuracy:  0.43902439024390244\n",
      "Match, Missed:  44 37 Accuracy:  0.5432098765432098\n",
      "Match, Missed:  39 42 Accuracy:  0.48148148148148145\n",
      "\n",
      "Validating Data\n",
      "Accuracy:  0.4268292682926829\n"
     ]
    }
   ],
   "source": [
    "# K fold crossvalidation on Player Dataset\n",
    "\n",
    "# add one for validation\n",
    "k = 5 + 1\n",
    "\n",
    "# Create k clusters and randomly initalize them\n",
    "data_folds = []\n",
    "label_folds = []\n",
    "for fold in range(0, k):\n",
    "    data_folds.append([])\n",
    "    label_folds.append([])\n",
    "\n",
    "for index, x in enumerate(player_data):\n",
    "    data_folds[index % k].append(x)\n",
    "    label_folds[index % k].append(player_labels[index])\n",
    "\n",
    "# Take out a validation fold\n",
    "data_val = data_folds.pop(0)\n",
    "label_val = label_folds.pop(0)\n",
    "\n",
    "best_mean = None\n",
    "best_cov = None\n",
    "best_acc = 0\n",
    "    \n",
    "for index in range(0, k - 1):\n",
    "    # Create training and testing folds\n",
    "    temp_data = copy.deepcopy(data_folds)\n",
    "    test_data = temp_data.pop(index)\n",
    "    train_data = []\n",
    "    for fold in temp_data:\n",
    "        for data in fold:\n",
    "            train_data.append(data)\n",
    "    \n",
    "    \n",
    "    temp_label = copy.deepcopy(label_folds)\n",
    "    test_label = temp_label.pop(index)\n",
    "    train_label = []\n",
    "    for fold in temp_label:\n",
    "        for data in fold:\n",
    "            train_label.append(data)\n",
    "            \n",
    "            \n",
    "    # Player classifier trained on all data\n",
    "    player_classes, player_mean, player_cov = naive_bayes_learn(train_data, train_label)\n",
    "    pred = naive_bayes_predict(player_classes, player_mean, player_cov, test_data)\n",
    "    match = 0\n",
    "    missed = 0\n",
    "    for index in range(0, len(pred)):\n",
    "        if pred[index] == test_label[index]:\n",
    "            match += 1\n",
    "        else:\n",
    "            missed += 1\n",
    "    acc = match / (match + missed)\n",
    "    print(\"Match, Missed: \", match, missed, \"Accuracy: \", acc)\n",
    "    if acc > best_acc:\n",
    "        best_mean = player_mean\n",
    "        best_cov = player_cov\n",
    "print()\n",
    "\n",
    "print(\"Validating Data\")\n",
    "pred = naive_bayes_predict(player_classes, best_mean, best_cov, data_val)\n",
    "match = 0\n",
    "missed = 0\n",
    "for index in range(0, len(pred)):\n",
    "    if pred[index] == label_val[index]:\n",
    "        match += 1\n",
    "    else:\n",
    "        missed += 1\n",
    "acc = match / (match + missed)\n",
    "print(\"Accuracy: \", acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match, Missed:  25 0 Accuracy:  1.0\n",
      "Match, Missed:  24 1 Accuracy:  0.96\n",
      "Match, Missed:  25 0 Accuracy:  1.0\n",
      "Match, Missed:  24 1 Accuracy:  0.96\n",
      "Match, Missed:  24 1 Accuracy:  0.96\n",
      "\n",
      "Validating Data\n",
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "# K fold crossvalidation on Player Dataset with one validation set\n",
    "\n",
    "# add one for validation\n",
    "k = 5 + 1\n",
    "\n",
    "# Create k clusters and randomly initalize them\n",
    "data_folds = []\n",
    "label_folds = []\n",
    "for fold in range(0, k):\n",
    "    data_folds.append([])\n",
    "    label_folds.append([])\n",
    "\n",
    "for index, x in enumerate(iris_data):\n",
    "    data_folds[index % k].append(x)\n",
    "    label_folds[index % k].append(iris_label[index])\n",
    "\n",
    "# Take out a validation fold\n",
    "data_val = data_folds.pop(0)\n",
    "label_val = label_folds.pop(0)\n",
    "\n",
    "best_mean = None\n",
    "best_cov = None\n",
    "best_acc = 0\n",
    "\n",
    "for index in range(0, k - 1):\n",
    "    # Create training and testing folds\n",
    "    temp_data = copy.deepcopy(data_folds)\n",
    "    test_data = temp_data.pop(index)\n",
    "    train_data = []\n",
    "    for fold in temp_data:\n",
    "        for data in fold:\n",
    "            train_data.append(data)\n",
    "    \n",
    "    \n",
    "    temp_label = copy.deepcopy(label_folds)\n",
    "    test_label = temp_label.pop(index)\n",
    "    train_label = []\n",
    "    for fold in temp_label:\n",
    "        for data in fold:\n",
    "            train_label.append(data)\n",
    "            \n",
    "            \n",
    "    # Player classifier trained on all data\n",
    "    iris_classes, iris_mean, iris_cov = naive_bayes_learn(train_data, train_label)\n",
    "    pred = naive_bayes_predict(iris_classes, iris_mean, iris_cov, test_data)\n",
    "    match = 0\n",
    "    missed = 0\n",
    "    for index in range(0, len(pred)):\n",
    "        if pred[index] == test_label[index]:\n",
    "            match += 1\n",
    "        else:\n",
    "            missed += 1\n",
    "    acc = match / (match + missed)\n",
    "    print(\"Match, Missed: \", match, missed, \"Accuracy: \", acc)\n",
    "    if acc > best_acc:\n",
    "        best_mean = iris_mean\n",
    "        best_cov = iris_cov\n",
    "print()\n",
    "\n",
    "print(\"Validating Data\")\n",
    "pred = naive_bayes_predict(iris_classes, best_mean, best_cov, data_val)\n",
    "match = 0\n",
    "missed = 0\n",
    "for index in range(0, len(pred)):\n",
    "    if pred[index] == label_val[index]:\n",
    "        match += 1\n",
    "    else:\n",
    "        missed += 1\n",
    "acc = match / (match + missed)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
